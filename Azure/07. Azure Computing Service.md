# Azure 컴퓨팅 서비스

### 개요

Azure 컴퓨팅은 클라우드 기반 애플리케이션을 실행하기 위한 주문형 컴퓨팅 서비스이다. 디스크, 프로세서, 메모리, 네트워킹 및 운영 체제와 같은 컴퓨팅 리소스를 제공한다. 리소스는 요청 시 제공되고, 일반적으로 몇 분 또는 몇 초 이내에 제공된다. 사용한 리소스에 대해 사용 기간의 요금만 지불하면 된다.

Azure는 개발 및 테스트, 애플리케이션 실행, 데이터 센터 확장을 위한 다양한 컴퓨팅 솔루션을 지원한다. 해당 서비스는 Linux, Windows Server, Microsoft SQL Server, Oracle, IBM 및 SAP를 지원한다. 또한 Azure에는 VM을 실행할 수 있는 많은 서비스가 있다. 각 서비스는 요구 사항에 따라 다양한 옵션을 제공한다. 주요 옵션은 다음과 같다. 

- Azure Virtual Machines
- Azure Container Instances
- Azure App Service
- Azure Functions(또는 ‘서버리스 컴퓨팅’)

### 1. 가상머신 ⭐️

가상머신은 물리적 컴퓨터의 소프트웨어 에뮬레이션이다. VM에는 가상 프로세서, 메모리, 스토리지 및 네트워킹 리소스가 포함된다. VM은 운영 체제를 호스트하고, 물리적 컴퓨터처럼 소프트웨어를 설치하고 실행할 수 있다. 원격 데스크톱 클라이언트를 사용할 때 실제처럼 VM을 사용하고 제어할 수 있다.

Azure Virtual Machines를 사용하여 클라우드에서 VM을 만들고 사용할 수 있다. Virtual Machines는 **Iaas**를 제공하며 다양한 방법으로 사용할 수 있다. 운영 체제 및 환경을 완전히 제어해야 하는 경우 VM을 선택하는 것이 좋다. 물리적 컴퓨터처럼 가상 머신에서 실행되는 모든 소프트웨어를 사용자 지정할 수 있다. 이 기능은 사용자 지정 소프트웨어 또는 사용자 지정 호스팅 구성을 실행하는 경우에 유용하다.



### 2. 가상 머신 크기 집합

가상 머신 확장 집합은 동일한 VM 세트를 배포 및 관리하는 데 사용할 수 있는 Azure 컴퓨팅 리소스이다. 모든 VM은 동일하게 구성되었으며 가상 머신 확장 집합은 실제 자동 크기 조정을 지원하도록 디자인되었다. VM의 사전 프로비저닝이 필요하지 않다. 이런 이유로, 빅 컴퓨팅, 빅 데이터 및 컨테이너화된 워크로드를 대상으로 하는 대규모 서비스를 손쉽게 빌드할 수 있다. 수요가 증가함에 따라 더 많은 VM 인스턴스가 추가될 수 있다. 수요가 감소함에 따라 VM 인스턴스가 제거될 수 있다. 이 프로세스는 수동, 자동, 또는 둘의 조합이 될 수 있다.



### 3. 컨테이너 및 Kubernetes ⭐️⭐️

#### 왜 컨테이너를 쓰는가?

가상 머신은 물리적 하드웨어에 필요한 투자 비용을 줄이는 좋은 방법이지만 가상 머신당 단일 운영체제로 제한된다. 단일 호스트 컴퓨터에서 애플리케이션의 여러 인스턴스를 실행하려는 경우에 컨테이너를 사용하는 것이 좋다.



#### 컨테이너란?

컨테이너는 **가상화 환경**이다. 단일 물리적 호스트에서 여러 가상 머신을 실행하는 것과 매우 유사하며, **단일 물리적 또는 가상 호스트에서 여러 컨테이너를 실행**할 수 있다. 가상 머신과 달리 컨테이너에 대한 운영 체제를 관리하지 않는다. 가상 머신은 연결하고 관리할 수 있는 운영 체제의 인스턴스인 것 같지만, **컨테이너는 저용량이며 동적 생성, 스케일 아웃 및 중지를 할 수 있도록 설계**되었다. 애플리케이션 수요 증가데 따라 가상 머신을 만들고 배포할 수 있지만, 컨테이너는 **수요 변화에 대응**할 수 있도록 설계되었다. 컨테이너를 사용하여 크래시 또는 하드웨어 중단이 발생한 경우 빠르게 다시 시작할 수 있다. 가장 많이 사용되는 컨테이너 엔진 중 하나는 Azure에서 지원하는 **Docker**이다.



#### 가상 머신과 컨테이너 비교

- 가상 머신은 한 번에 하나의 운영 체제만을 실행할 수 있다.
- 따라서 서로 다른 런타임 환경이 필요한 여러 응용 프로그램을 제대로 실행하기 위해서는 여러 개의 가상 머신이 필요할 수도 있다.
- 가상 머신은 전체 컴퓨터를 에뮬레이트하기 때문에 느리다.
- 이를 해결하기 위한 솔루션은 바로 컨테이너!
- 단일앱과 해당 종속성을 번들로 묶은 다음(컨테이너화), 이를 한 단위로 하여 컨테이너 호스트에 배포한다. 컨테이너 호스트는 운영체제 및 인프라 요구 사항을 추상화하는 표준화된 런타임 환경을 제공하므로 컨테이너화된 응용 프로그램이 다른 컨테이너화된 앱과 나란히 실행될 수 있다.
- 구별하기 쉬운 방법으로는, 가상 머신은 하드웨어를 가상화하지만, 컨테이너는 운영체제를 가상화한다.
- 이를 사용하면 가상 머신이 원래 제공한 격리를 희생하지 않고, 단일 호스트에서 여러 간단한 컨테이너를 실행할 수 있다.
- 또한 컨테이너화된 앱은 크기가 훨씬 더 작은 경향이 있다.
- 그리고 개발 런타임 환경이 프로덕션 환경과 똑같이 보일 수 있으므로 개발 프로세스가 간소화된다.
- 또 다른 장점은 컨테이너 클러스터 오케스트레이션으로 오케스트레이션될 수 있다는 점이다.
- 활용과 유연성에 따라 방식 결정하면 된다.

Container Instances 및 Azure Kubernetes Service는 컨테이너를 배포하고 관리하는 데 사용할 수 있는 Azure 컴퓨팅 리소스이다. 컨테이너는 간단하고 가상화된 애플리케이션 환경이다. 빠르게 동적으로 만들고, 스케일 아웃하고, 중지하도록 설계되어있다. 단일 가상 머신 호스트에서 컨테이너화된 애플리케이션의 여러 인스턴스를 실행할 수 있다.

#### Container Instances (ACI)

- 서버를 관리할 필요 없이 컨테이너 실행
- 주문형 컨테이너로 민첩성 증가
- 하이퍼바이저 격리를 통해 애플리케이션 보호



#### Azure Kubernetes Services(AKS)

컨테이너를 사용하여 응용 프로그램과 다른 프로세스를 호스트 하는 것이 주류가 되었다. 점점 더 많은 워크로드가 컨테이너로 전환함에 따라 대규모 수준으로 컨테이너화된 응용 프로글매의 요구를 처리하기 위한 관리 시스템이 필요하다. 컨테이너 기반 워크로드를 관리하는 데 가장 인기있는 옵션 중 하나가 Kubernetes이다.

물론 컨테이너 관리 자동화와 확장 가능한 API를 결합하여 클라우드 네이티브 응용 프로그램 관리 기능을 만든다. **Kubernetes는 본질적으로 단일 Kubernetes 클러스터 노드에서 하나 이상의 컨테이너로 구성될 수 있는 Pod의 배치를 관리한다.** 또한 이러한 Pod 중 하나가 충돌하면 Kubernetes에서 해당 Pod의 새 인스턴스를 만들 수 있다. 클러스터 노드가 제거되면 Kubernetes에서 영향을 받는 워크로드를 클러스터의 다른 노드로 이동할 수 있다. 그 외에도 Kubernetes Pod는 규모 요구 사항에 맞게 더 많거나 더 적은 처리량을 제공하도록 크기를 조정할 수 있다. (**Kubernetes Scailing**) 그리고 크기 조정 작업은 Kubernetes 수평 Pod 자동 크기 조정을 통해 수동 또는 자동으로 트리거될 수 있다. 마지막으로, 응용 프로그램을 업데이트해야 하는 경우 Kubernetes는 가동 중지 시간을 최소화하기 위해 업데이트 배포를 지그재그 형태로 배치할 수 있다. (**Kubernetes and staggering update deployment**) 또한 업데이트에 문제가 있는 경우 Kubernetes는 이전 버전으로 롤백할 수 있다. Kubernetessms Pod 관리와 함께 컨테이너 저장소 및 네트워킹을 관리할 수 있다.(**Kubernetes storage and networking management**) Kubernetes 영구적 볼륨은 하나 이상의 컨테이너에 데이터 저장소를 제공하는 데 사용할 수 있다. 이 구성을 사용하면 컨테이너에서 응용 프로그램 데이터를 읽고 쓸 수 있으며 여러 Pod 인스턴스 간에 이 데이터를 유지할 수 있다. 즉, Kubernetes에서 실행되는 응용 프로그램에서 데이터 저장 및 검색을 위해 Azure Storage 또는 Azure Cosmos DB와 같은 클라우드 기반 저장소 및 데이터 시스템을 사용하는 것이 일반적이다. 네트워킹과 관련하여 Kubernetes 네트워크 플러그 인은 Pod를 인터넷에 공개하고, Pod의 여러 복제본 간에 트래픽의 부하를 분산하고, 네트워크 격리 및 정책 기반 네트워크 보안과 같은 기능을 제공한다. 또한 이러한 네트워크 플러그 인은 Kubernetes 클러스터의 Pod 간 통신 및 이름 확인을 관리한다. Kubernetes의 기능은 기본 제공 기능으로 제한되지 않는다. 추가 기능은 Kubernetes API를 확장하는 다양한 방법을 사용하여 만들 수 있다. (**Extending Kubernetes functionality**)



#### 솔루션에서 컨테이너 사용

컨테이너는 종종 *마이크로 서비스 아키텍처*를 사용하여 솔루션을 만드는 데 사용된다. 이 아키텍처에서 솔루션을 더 작고 독립적인 조각으로 분할할 수 있다. 예를 들어, 웹 사이트를 프런트 엔드를 호스트하는 컨테이너, 백 엔드를 호스트하는 컨테이너 및 스토리지용 컨테이너로 분할할 수 있다. 분할 후에는 앱을 논리적 섹션으로 구분하여 독립적으로 유지 관리, 확장 또는 업데이트할 수 있다.

웹 사이트 백 엔드가 용량에 도달했지만 프런트 엔드와 스토리지는 부하가 크지 않은 경우를 가정해보자. 다음과 같이 할 수 있다.

- 성능 향상을 위해 백 엔드를 별도로 스케일링한다.
- 다른 스토리지 서비스를 사용하기로 결정한다.
- 또는 애플리케이션의 나머지 부분에 영향을 주지 않고 스토리지 컨테이너를 바꾼다.

#### 마이크로 서비스란?

규모가 작고 잘 정의된 범위의 웹 서비스이며 다른 웹 서비스와 느슨하게 결합되어 있다. 일반적으로 조직에서는 하나의 마이크로 서비스를 구축하는 것이 아니라, 오히려 각각 자립적으로 단일 비즈니스 기능을 구현하는 마이크로 서비스의 컬렉션으로 구성된 마이크로 서비스 아키텍처를 채택한다. 각 서비스는 작은 개발 팀이 관리할 수 있는 개별 코드베이스이다. 실제로 마이크로 서비스는 동일한 기술 스택, 라이브러리 또는 프레임워크를 공유할 필요가 없으므로 각 팀에서 해당 작업에 적합한 도구를 선택할 수 있다. 즉 단일 개발 팀이 서비스를 빌드, 테스트 및 배포할 수 있다. 그 결과, 연속적인 혁신과 더 빠른 릴리스 주기가 가능하다. 이제는 팀에서 하나의 서비스에만 집중할 수 있으며, 각 서비스에서 더 작은 범위를 사용하여 코드베이스를 더 쉽게 이해할 수 있고, 이에 따라 새로운 사람이 오더라도 쉽게 확장하고 시작할 수 있다. 이제 각 마이크로 서비스는 이 경로를 통해 조직의 다른 모든 마이크로 서비스와 독립적으로 배포될 수 있다. 팀이 전체 응용 프로그램을 다시 빌드한 후 재배포하지 않고도 기존 서비스를 업데이트할 수 있다. 또한 문제가 발생하면 쉽게 롤백하거나 롤포워드하여 업데이트할 수도 있다. 가장 좋은 것은 이렇게 하면 버그 수정 및 기능 릴리스를 더 쉽게 관리할 수 있고 위험이 줄어든다. 배포 전략은 각 마이크로 서비스를 독립적으로 크기 조정할 수 있음을 의미한다. 이 효율성의 이점은 각 마이크로 서비스가 자체 데이터 또는 외부 상태를 유지하면서 일반적인 리포지토리 계층의 영향을 받지 않는다. 실제로 일부 마이크로 서비스 전문가는 각 마이크로 서비스에 별도의 데이터베이스가 있어야 한다고 주장한다. 상호 종속성 없이 각 마이크로 서비스를 완전히 자율적으로 운영하면서 결함격리계층이 제공된다. 덕분에 한 서비스가 다운되더라도 반드시 전체 응용 프로그램 작동이 중단되는 것이 아니다. 

그렇다면 각 마이크로 서비스 자체가 섬이라면 단일 응용 프로그램에서 여러 마이크로 서비스를 사용해야할 때 어떤 일이 발생할까?

**마이크로 서비스는 잘 정의된 API를 상요하여 서로 통신할 수 있다.**

각 서비스의 내부 구현 세부 정보는 해당 인터페이스에 저장된다. 그러나 일반적으로는 이러한 상호종속성을 줄이고, 상위 애플리케이션에 하위의 다양한 마이크로 서비스 호환을 조정하고 결과를 결합하는 오케스트레이션 또는 관리 기능을 도입하고 싶어한다.

마이크로 서비스 아키텍처는 일부 문제를 해결하며 빠른 릴리스 속도가 필요한 큰 응용 프로그램이 있거나 확장성이 커야하는 복잡한 응용 프로그램이 있거나, domain이 richg한 경우에 유용하다. 



- 기존 애플리케이션을 클라우드로 마이그레이션하거나, 기계 학습을 사용하는 복잡한 애플리케이션을 빌드하거나, 마이크로 서비스 아키텍처가 제공하는 민첩성을 활용
  - 애플리케이션을 컨테이너로 변환하고 Azure Container Registry에 컨테이너 이미지를 게시한다.
  - 사용자가 Azure Portal 또는 명령줄을 사용하여 컨테이너를 AKS 클러스터에 배포한다.
  - Azure Active Directory를 사용하여 AKS 리소스에 대한 액세스를 제어한다.
  - Open Service Broker for Azure를 사용하여 Azure Database for MySQL 같은 SLA 지원 Azure 서비스에 쉽게 액세스한다.
  - 필요에 따라 AKS를 VNET 가상 네트워크와 함께 배포한다.

![스크린샷 2021-01-30 오후 2.30.27](/Users/Eunji/TIL/Azure/images/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202021-01-30%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%202.30.27.png)

#### AKS용 보안 DevOps

- DevOps와 Kubernetes를 함께 사용하면 더 좋다. Azure에서 Kubernetes와 함께 보안 DevOps를 구현하면 속도와 보안을 균형 있게 적용하고 코드를 대규모로 더 빠르게 제공할 수 있다. 동적 정책 컨트롤이 포함된 CI/CD를 사용하여 개발 프로세스에 보호책을 적용하고 지속적인 모니터링으로 피드백 루프를 가속화한다. Azure Policy를 통해 중요한 정책을 적용하면서 Azure Pipelines를 사용하여 빠르게 제공한다. Azure는 빌드 및 릴리스 파이프라인에 대한 실시간 가시성과 규정 준수 감사 및 재구성을 적용하는 기능을 제공한다.
  - 같은 Kubernetes 클러스터에서 애플리케이션의 서로 다른 부분을 함께 빠르게 반복, 테스트 및 디버그함
  - 코드가 GitHub 리포지토리에 병합되고, 그 후 Azure Pipelines에 의해 자동화된 빌드 및 테스트가 실행됨
  - 컨테이너 이미지가 Azure Container Registry에 등록됨.
  - Kubernetes 클러스터는 Terraform 같은 도구를 사용하여 프로비저닝됨. Terraform에 의해 설치된 Helm 차트는 앱 리소스 및 구성의 필요한 상태를 정의함
  - 운영자가 배포를 관리하는 정책을 AKS 클러스터에 적용함
  - 릴리스 파이프라인은 각 코드 변경 내용을 사용하여 미리 정의된 배포 전략을 자동으로 실행함
  - Azure Policy를 통해 정책 적용 및 감사가 CI/CD 파이프라인에 추가됨
  - Azure Monitor를 사용하여 앱 원격 분석, 컨테이너 상태 모니터링 및 실시간 로그 분석이 수행됨
  - 문제를 해결하는 데 인사이트가 사용되고 다음 스프린트 플랜에 피드됨

![스크린샷 2021-01-30 오후 2.37.28](/Users/Eunji/TIL/Azure/images/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202021-01-30%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%202.37.28.png)

### 4. App Service 

Azure App Service를 사용하면 모든 플랫폼에서 실행되는 엔터프라이즈급 웹, 모바일 및 API 앱을 신속하게 빌드, 배포 및 스케일링할 수 있다. 완전 관리형 플랫폼을 사용하여 인프라 유지 고나리를 수행하는 동안 엄격한 성능, 확장성, 보안 및 규정 준수 요구 사항을 충족할 수 있다. App Service는 **Paas**제공이다.

Tailwind Traders를 대상으로 한 조사에서 애플리케이션을 가상화할 수 있는 두 가지 방법을 살펴보았다. 또 다른 대안으로 애플리케이션의 프런트 엔드 웹 사이트를 Azure App Service에 배포하는 방법이 있으며, 이를 통해 쉽게 애플리케이션 수요에 대응할 수 있다.

App Service를 사용하면 인프라를 관리할 필요 없이 원하는 프로그래밍 언어로 웹앱, 백그라운드 작업, 모바일 백 엔드 및 RESTful API를 빌드하고 호스트할 수 있다. 자동 확장 기능과 고가용성을 제공한다. App Service는 Windows 및 Linux를 지원하며, GitHub, Azure DevOps 또는 Git 리포지토리에서 자동화된 배포를 사용하여 지속적인 배포 모델을 지원한다.

### 5. 함수

Functions는 기본 플랫폼이나 인프라가 아닌, 서비스를 실행하는 코드에 관해서만 관심이 있는 경우에 이상적이다. Azure Functions는 (주로 REST 요청을 통한) 이벤트, 타이머 또는 다른 Azure 서비스로부터 받은 메세지에 대한 응답으로 작업을 수행해야 하는 경우, 그리고 해당 작업을 수초 이내에 빠르게 완료할 수 있는 경우에 주로 사용된다.

Tailwind Traders의 여러 동료 개발자와 논의한 후 일부 애플리케이션 로직이 이벤트 기반임을 확인했다. 즉, 긴 시간 동안 애플리케이션이 특정 입력을 기다린 다음에야 처리를 수행한다. 비용을 줄이기 위해 애플리케이션이 입력을 기다리는 시간에 요금을 지급하지 않으려고 한다. 이를 염두에 두고 Azure Functions가 도움이 될 수 있는지 조사하기로 결정했다.



#### Serverless Computing

서버리스 컴퓨팅의 목적은 애플리케이션을 고객에게 제공하는 데 집중할 수 있도록 부담될 수 있는 서버 관리 작업을 대신 처리하여 사용자를 돕는 것이다. 사실 서버리스 컴퓨팅은 실제로 사용되는 서버가 있으므로 완전히 올바른 명칭이라고 볼 수 없다. 정확한 의미는 사용자를 대신해 서버 관리 작업이 이미 처리됨을 나타낸다. 

‘서버리스’ 컴퓨팅은 서버, 인프라 및 운영 체제의 추상화입니다. Azure에서는 서버리스 컴퓨팅을 통해 서버 인프라 관리 및 수요에 따른 리소스 할당 및 할당 해제를 처리합니다. 인프라는 사용자의 책임이 아닙니다. 크기 조정 및 성능이 자동으로 처리됩니다. 사용하는 정확한 리소스에 대해서만 요금이 청구됩니다. 용량을 예약할 필요도 없습니다. 

1. No infrastructure management
2. Scalability
3. Only pay for what you use

구현에는 두 가지 방식이 있다.

1. Azure Functions

기본 플랫폼이나 인프라가 아닌, 서비스를 실행하는 코드에 관해서만 관심이 있는 경우에 Azure Functions를 사용하는 것이 이상적입니다. 함수는 주로 REST 요청을 통한 이벤트, 타이머 또는 다른 Azure 서비스로부터 받은 메시지에 대한 응답으로 작업을 수행해야 하는 경우, 그리고 해당 작업을 수초 이내에 빠르게 완료할 수 있는 경우에 주로 사용됩니다.

2. Azure Logic Apps

논리 앱은 함수와 유사합니다. 둘 다 이벤트를 기반으로 논리를 트리거할 수 있습니다. 함수가 코드를 실행하는 경우 논리 앱은 비즈니스 시나리오를 자동화하도록 설계되고 미리 정의된 논리 블록에서 빌드된 ‘워크플로’를 실행합니다.

모든 Azure 논리 앱 워크플로는 특정 이벤트가 발생하거나 사용 가능한 새 데이터가 특정 기준을 충족할 때 실행되는 트리거를 통해 시작됩니다. 워크로드가 주기적으로 실행되는 빈도를 개발자가 지정할 수 있도록 많은 트리거가 기본적인 일정 예약 기능을 제공합니다. 트리거가 실행될 때마다 Logic Apps 엔진은 워크플로의 작업을 실행하는 논리 앱 인스턴스를 만듭니다. 또한 이러한 작업에는 조건부 명령문, 전환 명령문, 루프, 분기 등의 데이터 변환 및 흐름 컨트롤이 포함될 수 있습니다.

